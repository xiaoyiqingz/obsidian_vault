> [原文](https://zhuanlan.zhihu.com/p/630918550) 

## 背景

近半年来AI非常火爆，我们深刻地体会到GPT类产品已经切实地在改变我们的生活和工作方式。我也比较关注AI相关的开源技术，最近看到了两个开源库给了我非常大的灵感：

1. **LangChain**：这个库把AI开发中可能会用到的相关技术都抽象成一个个小的模块，很多工具函数都开箱即用。官网里的一个向量数据库使用的例子给我留下了深刻的印象：从本地文件的读取、文本内容的拆分、向量的存储到相似向量的检索， **这整个过程每个步骤都是几个非常简洁明了的函数调用，整个流程几十行代码**。不禁让我感叹：这么容易？有了这AI开发我也能搞啊！
2. **AutoGPT**：在给AutoGPT设定一个目标后，它会做类OKR分解，执行，检查完成情况，制定优化计划，依此 通过不断地自我 prompt 达成设定目标。在学习它源码的时候有一点对我的启发很大：首先代码中预定义了一堆command脚本，**在和ChatGPT通话过程中会让它 回复{”command”: “xxx”, “thoughts”: ‘xxx’} 这样的 JSON，解析后可以继续执行本地脚本，从而实现自主执行 , 感觉这是这个项目的精华所在**。其实看到 JSON ， 作为前端开发是很兴奋了，通过调戏 LLM 让他给出 **JSON** （Model As A Service） **，纯前端就能玩出很多花活呢！**

想到上面几个灵感比较兴奋，于是趁着周末两天撸了个“套壳”应用。同时也验证下**利用 Prompt Engineering 调戏 LLM 返回 JSON 的方式玩出花活**的可能性

有观察市面上比较火的文档类问答工具 ChatPDF 和 ChatDocs 等产品，觉得非常酷。因此，我打算简单实现类似的功能：**在应用程序的某个目录下放置一些文件（PDF、TXT、DOC、EXCEL），然后在聊天窗口中提出任何文档相关的问题，机器人将总结好答案并回复你**。此外，我还设计了一些小交互（如文章开头 GIF 所示）：让机器人在回复答案的同时说明参考原文，并联想一些类似的问题，方便用户持续提问。

## **实现分析**

**主要聚焦在两个问题： 如何调教 LLM 让它学会本地的知识， “套壳应用”工程化技术选型**

1.**如何喂数据给 LLM？**

Fine-Turning

说到让大语言模型学会一些本地知识，首先会想到的是“训练”。通常的做法是为机器准备固定格式的数据集，类似于  `[{question: 'xxx', answer: 'xxx'}, ...]` ，然后使用 Fine-Tuning 的方法对非结构化数据进行训练。但对于像我这样的外行来说，去对数据做预处理和特征工程不是一种合适的解法。

Embedding

Embedding的理解是将高维数据向量化的过程。在LangChain中，有现成的工具函数可以完成这个任务。众所周知，GPT3.5的API有4K token 的长度限制，因此直接将所有的PDF文件一股脑地塞给LLM是不可行的，肯定超过了这个长度限制。LangChain中的 **Document Loaders、Text Splitters、Vector Stores** 提供了一种巧妙的方法来绕过这个4K token的限制。大致的工作原理是：首先在本地启动一个向量数据库，用来存储所有本地文档。然后，在进入GPT之前，先在本地进行一次相似度内容搜索。最后，将空间距离最近的几个答案嵌入提问中，交给LLM处理。